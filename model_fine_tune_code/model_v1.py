# -*- coding: utf-8 -*-
"""NLP_Learning.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dIrIo4la5u6H_IBC2L1ZC1susehHYURV
"""

import torch
import pandas as pd
from datasets import load_dataset, Dataset, Value
from sklearn.model_selection import train_test_split
from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification, TrainingArguments, Trainer
import numpy as np
from sklearn.metrics import f1_score, roc_auc_score, accuracy_score

# --- 1.1 Load Data and Get Labels ---
# GoEmotions has 28 labels (27 emotions + neutral)
dataset = load_dataset("go_emotions", "simplified")
emotion_labels = dataset["train"].features["labels"].feature.names
NUM_LABELS = len(emotion_labels) # Should be 28

# Create mappings for labels
id2label = {i: label for i, label in enumerate(emotion_labels)}
label2id = {label: i for i, label in enumerate(emotion_labels)}

print(f"Total number of labels: {NUM_LABELS}")
print(f"Example labels: {emotion_labels[:5]}")

# --- 1.2 Function to Convert Labels to Multi-Hot Vector ---
def convert_labels_to_multihot(batch):
    # This creates a NumPy array of floats (dtype=np.float32)
    label_vector = np.zeros(NUM_LABELS, dtype=np.float32)

    for label_id in batch["labels"]:
        label_vector[label_id] = 1.0 # Ensures value is a float

    # Return a Python list (or np array) which will be cast later
    return {"labels": label_vector.tolist()} # return as list/np array for the cast step

# --- 1.3 Apply Conversion and Split Data ---

# Map the function to all splits (train, validation, test)
dataset_encoded = dataset.map(convert_labels_to_multihot)

# The 'labels' feature is now an array/vector of 28 floats
print("\nExample of Multi-Hot Label Vector (first sample):")
print(dataset_encoded["train"][0]["labels"])

# --- 2.1 Load Tokenizer ---
model_checkpoint = "distilbert-base-uncased"
tokenizer = DistilBertTokenizerFast.from_pretrained(model_checkpoint)

# Set max length to 512, which is the DistilBERT limit.
# Long journal entries will be truncated.
MAX_LENGTH = 512

# --- 2.2 Tokenization Function ---
def tokenize_and_prepare_input(examples):
    return tokenizer(
        examples["text"],
        truncation=True,
        padding="max_length", # Pad shorter texts to MAX_LENGTH
        max_length=MAX_LENGTH
    )

# --- 2.3 Apply Tokenization ---
# Remove the original 'text' and integer 'labels' column, keeping only the 'input_ids', 'attention_mask', and new float 'labels'
tokenized_datasets = dataset_encoded.map(
    tokenize_and_prepare_input,
    batched=True,
    remove_columns=['text', 'id']
)

# 1. Define the correct feature type for the labels column: a Sequence of Floats
# We copy the existing features and only change the type of the 'labels' column
new_features = tokenized_datasets['train'].features.copy()
# The labels column MUST be a sequence of floats for the multi-label loss function
new_features['labels'] = [Value('float32')]

# 2. Cast the entire dataset splits to the new features
tokenized_datasets = tokenized_datasets.cast(new_features)

# Change the format of the labels column to PyTorch tensors
tokenized_datasets.set_format("torch", columns=["input_ids", "attention_mask", "labels"])

print("\nTokenized Dataset Features:")
print(tokenized_datasets["train"].column_names)

# --- 3.1 Load Pre-trained Model with Classification Head ---
model = DistilBertForSequenceClassification.from_pretrained(
    model_checkpoint,
    num_labels=NUM_LABELS,
    id2label=id2label,
    label2id=label2id,
    # This is crucial for multi-label classification
    problem_type="multi_label_classification"
)

# --- 3.2 Verify Output Head ---
# Check the final layer to confirm it matches the number of labels
print("\nModel Classifier Head Output Dimension Check:")
# Should output 28 raw scores (logits)
print(f"Expected: {NUM_LABELS}, Actual: {model.classifier.out_features}")

# Note on Loss: When problem_type="multi_label_classification" is set,
# the Hugging Face Trainer **automatically** uses
# torch.nn.BCEWithLogitsLoss() for the loss calculation.

# --- 4.1 Define Evaluation Metrics (Crucial for Multi-Label) ---
def compute_metrics(eval_pred):
    # Logits are the raw outputs (before sigmoid)
    logits, labels = eval_pred

    # 1. Apply Sigmoid to get probabilities (percentages)
    probabilities = 1 / (1 + np.exp(-logits))

    # 2. Convert probabilities to hard predictions (0 or 1)
    # A common threshold for multi-label is 0.5
    predictions = (probabilities > 0.5).astype(int)

    # 3. Calculate metrics
    # Micro-F1 is a good overall measure for multi-label
    micro_f1 = f1_score(labels, predictions, average="micro")

    # ROC AUC is another strong metric for multi-label probability prediction
    try:
        roc_auc = roc_auc_score(labels, probabilities, average="micro")
    except ValueError:
        roc_auc = 0.0  # Handle case where only one class is present

    return {
        "micro_f1": micro_f1,
        "roc_auc": roc_auc,
    }
# --- 4.2 Define Corrected Training Arguments ---
training_args = TrainingArguments(
    output_dir="./results_goemotions",
    num_train_epochs=3,
    per_device_train_batch_size=16,
    per_device_eval_batch_size=16,
    warmup_steps=500,
    weight_decay=0.01,
    logging_dir='./logs',
    logging_steps=500,
    eval_strategy="epoch",
    save_strategy="epoch",    
    load_best_model_at_end=True,
    report_to="none"
)

# --- 4.3 Initialize and Run Trainer ---
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=tokenized_datasets["train"],
    eval_dataset=tokenized_datasets["validation"],
    processing_class=tokenizer,
    compute_metrics=compute_metrics
)

trainer.train()
print("\nTrainer successfully initialized. Ready to fine-tune.")

# --- âœ… Save the fine-tuned model and tokenizer ---
save_path = "./emotion_model"
model.save_pretrained(save_path)
tokenizer.save_pretrained(save_path)

print(f"\nModel and tokenizer saved to {save_path}")

# --- 5.1 Load the Fine-Tuned Model and Tokenizer ---
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)

sample_journal_entry = "I finished the project today! I'm so proud of myself and excited for what's next, but I'm also relieved the stress is over."

# --- 5.1 Tokenize Input ---
test_input = tokenizer(
    sample_journal_entry,
    truncation=True,
    padding="max_length",
    max_length=MAX_LENGTH,
    return_tensors="pt"
).to(device)

# --- 5.2 Generate Prediction (Logits) ---
model.eval() # Set model to evaluation mode
with torch.no_grad():
    outputs = model(**test_input)
    # The output is a tensor of 28 raw scores (logits)
    logits = outputs.logits

# --- 5.3 Convert Logits to Probabilities (Percentages) ---
# Apply the Sigmoid function to get probabilities [0, 1]
probabilities = torch.sigmoid(logits).squeeze().cpu().numpy()

# --- 5.4 Map Percentages to Emotion Labels ---
results = {}
for i, emotion in id2label.items():
    # Convert probability (e.g., 0.95) to percentage (e.g., 95.00%)
    percentage = probabilities[i] * 100
    results[emotion] = percentage

# Sort and print the top 5 predicted emotions/percentages
sorted_results = sorted(results.items(), key=lambda item: item[1], reverse=True)

print("\n--- Emotion Detection Results (Percentages) ---")
for emotion, percent in sorted_results:
    print(f"**{emotion.capitalize()}**: {percent:.2f}%")

print("\n--- Full Multi-Label Prediction Vector ---")
print(f"Probabilities (shape {probabilities.shape}):\n{probabilities}")

#!zip -r emotion_model.zip ./emotion_model

